{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "NB_DIR = os.getcwd()\n",
    "ROOT_DIR = os.path.dirname(NB_DIR)\n",
    "\n",
    "sys.path.append(ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from core.io_ops import load_pickle\n",
    "from core.augmentation import cleanse_data\n",
    "from core.data_model import Patients\n",
    "from ontology_src import ArtifactPath\n",
    "\n",
    "disease_data = load_pickle(ArtifactPath.diseases)\n",
    "patient_data = load_pickle(ArtifactPath.patients)\n",
    "ontology = load_pickle(ArtifactPath.hpo_definition)\n",
    "disease_data, patient_data = cleanse_data(disease_data, patient_data)\n",
    "\n",
    "train_val_patients_list, test_patients_list = train_test_split(\n",
    "    patient_data.data, random_state=2023\n",
    ")\n",
    "train_patients_list, val_patients_list = train_test_split(\n",
    "    train_val_patients_list, random_state=2023\n",
    ")\n",
    "train_patients = Patients(train_patients_list)\n",
    "val_patients = Patients(val_patients_list)\n",
    "test_patients = Patients(test_patients_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heon/anaconda3/envs/symptom/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from core.datasets import (\n",
    "    StochasticPairwiseDataset,\n",
    "    collate_for_stochastic_pairwise_eval,\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from core.networks import Transformer\n",
    "\n",
    "params = {\n",
    "    \"output_size\": 128,\n",
    "    \"hidden_dim\": 2048,\n",
    "    \"input_size\": 1536,\n",
    "    \"n_layers\": 32,\n",
    "    \"nhead\": 32,\n",
    "    \"batch_first\": False,\n",
    "}\n",
    "best_model = Transformer(**params)\n",
    "best_model.load_state_dict(\n",
    "    torch.load(\n",
    "        \"/data/tyler_dev/working_dir/sym/symptom_similarity/data/81fcf4f39e57422db4debfeac61b01f0/val_top100_0.584.ckpt\"\n",
    "    )\n",
    ")\n",
    "best_model.eval()\n",
    "best_model = best_model.cuda()\n",
    "\n",
    "test_dataset = StochasticPairwiseDataset(\n",
    "    test_patients,\n",
    "    disease_data,\n",
    "    max_len=15,\n",
    ")\n",
    "test_dataset.validate()\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_for_stochastic_pairwise_eval,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8181/8181 [01:44<00:00, 78.19it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from core_3asc.metric import topk_recall\n",
    "\n",
    "cached_vector = {}\n",
    "whole_disease = test_dataset.disease_tensors\n",
    "with torch.no_grad():\n",
    "    for disease_id, tensor in tqdm(whole_disease.items()):\n",
    "        cached_vector[disease_id] = best_model(tensor.cuda()).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from core.io_ops import read_json\n",
    "from core.data_model import HPO, HPOs, Patient, Patients\n",
    "\n",
    "benchmark_patients_container = list()\n",
    "for path in glob.glob(\"/home/heon/repositories/symptom_similarity/data/phenopackets/*\"):\n",
    "    p_data = read_json(path)\n",
    "    \n",
    "    patient_id = p_data[\"id\"]\n",
    "    disease_ids = {disease[\"term\"][\"id\"] for disease in p_data[\"diseases\"]}\n",
    "    hpos = ontology[[phenotype[\"type\"][\"id\"] for phenotype in p_data[\"phenotypicFeatures\"]]]\n",
    "\n",
    "    benchmark_patients_container.append(\n",
    "        Patient(\n",
    "            id=patient_id,\n",
    "            hpos=hpos,\n",
    "            disease_ids=disease_ids\n",
    "        )\n",
    "    )\n",
    "\n",
    "benchmark_patients = Patients(benchmark_patients_container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.data_model import Diseases\n",
    "omim_diseases = Diseases([disease for disease in disease_data if disease.id.startswith(\"OMIM\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchmark.pheno2disease import Pheno2Disease\n",
    "pheno2disease = Pheno2Disease()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/384 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 47/384 [02:36<18:41,  3.33s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[82], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, omim_disease \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(omim_diseases):\n\u001b[1;32m     16\u001b[0m     scores_model[i] \u001b[38;5;241m=\u001b[39m cosine_sim(p_vector, cached_vector[omim_disease\u001b[38;5;241m.\u001b[39mid]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m---> 17\u001b[0m     scores_pheno2disease[i] \u001b[38;5;241m=\u001b[39m \u001b[43mpheno2disease\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_pheno2disease\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43momim_disease\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m omim_disease\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01min\u001b[39;00m patient\u001b[38;5;241m.\u001b[39mdisease_ids:\n\u001b[1;32m     20\u001b[0m         label[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/repositories/symptom_similarity/benchmark/pheno2disease.py:67\u001b[0m, in \u001b[0;36mPheno2Disease.get_pheno2disease\u001b[0;34m(self, patient, disease)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_pheno2disease\u001b[39m(\u001b[38;5;28mself\u001b[39m, patient, disease) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m     66\u001b[0m     sum_sym_p, sum_ic_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sym(patient, disease)\n\u001b[0;32m---> 67\u001b[0m     sum_sym_d, sum_ic_d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_sym\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdisease\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     sym_pd \u001b[38;5;241m=\u001b[39m (sum_sym_p \u001b[38;5;241m+\u001b[39m sum_sym_d) \u001b[38;5;241m/\u001b[39m (sum_ic_p \u001b[38;5;241m+\u001b[39m sum_ic_d)\n\u001b[1;32m     70\u001b[0m     pheno2disease \u001b[38;5;241m=\u001b[39m sym_pd \u001b[38;5;241m+\u001b[39m (sum_sym_p \u001b[38;5;241m/\u001b[39m sum_ic_p)\n",
      "File \u001b[0;32m~/repositories/symptom_similarity/benchmark/pheno2disease.py:49\u001b[0m, in \u001b[0;36mPheno2Disease.get_sym\u001b[0;34m(self, patient, disease)\u001b[0m\n\u001b[1;32m     47\u001b[0m sum_sym \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     48\u001b[0m sum_ic \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p_sym \u001b[38;5;129;01min\u001b[39;00m patient\u001b[38;5;241m.\u001b[39mhpos:\n\u001b[1;32m     50\u001b[0m     max_sim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m d_sym \u001b[38;5;129;01min\u001b[39;00m disease\u001b[38;5;241m.\u001b[39mhpos:\n",
      "File \u001b[0;32m~/repositories/symptom_similarity/core/data_model.py:58\u001b[0m, in \u001b[0;36mBase.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"iteration을 위한 magic method\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \n\u001b[1;32m     44\u001b[0m \u001b[38;5;124;03mRaises:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata):\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_index\u001b[49m]\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def cosine_sim(v1, v2)->float:\n",
    "    return v1 @ v2 / np.linalg.norm(v1) * np.linalg.norm(v1)\n",
    "\n",
    "patient_scores = dict()\n",
    "for patient in tqdm(benchmark_patients):\n",
    "    label = np.zeros(len(omim_diseases))\n",
    "    scores_model = np.zeros(len(omim_diseases))\n",
    "    scores_pheno2disease = np.zeros(len(omim_diseases))\n",
    "    p_vector = best_model(\n",
    "        torch.from_numpy(patient.hpos.vector).cuda().float()\n",
    "    ).squeeze(0).detach().cpu().numpy()\n",
    "    \n",
    "    patient_score = dict()\n",
    "    for i, omim_disease in enumerate(omim_diseases):\n",
    "        scores_model[i] = cosine_sim(p_vector, cached_vector[omim_disease.id].detach().cpu().numpy())\n",
    "        scores_pheno2disease[i] = pheno2disease.get_pheno2disease(patient, omim_disease)\n",
    "\n",
    "        if omim_disease.id in patient.disease_ids:\n",
    "            label[i] = 1\n",
    "    \n",
    "    patient_score[\"model\"] = scores_model\n",
    "    patient_score[\"p2d\"] = scores_pheno2disease\n",
    "    patient_score[\"label\"] = label\n",
    "    patient_scores[patient.id] = patient_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core_3asc.metric import AverageMeter, topk_recall\n",
    "model_top1 = AverageMeter()\n",
    "model_top5 = AverageMeter()\n",
    "model_top10 = AverageMeter()\n",
    "model_top50 = AverageMeter()\n",
    "p2d_top1 = AverageMeter()\n",
    "p2d_top5 = AverageMeter()\n",
    "p2d_top10 = AverageMeter()\n",
    "p2d_top50 = AverageMeter()\n",
    "\n",
    "for id, patient_score in patient_scores.items():\n",
    "    model_top1.update(topk_recall(patient_score[\"model\"], patient_score[\"label\"], k=1))\n",
    "    model_top5.update(topk_recall(patient_score[\"model\"], patient_score[\"label\"], k=5))\n",
    "    model_top10.update(topk_recall(patient_score[\"model\"], patient_score[\"label\"], k=10))\n",
    "    model_top50.update(topk_recall(patient_score[\"model\"], patient_score[\"label\"], k=50))\n",
    "    \n",
    "    p2d_top1.update(topk_recall(patient_score[\"p2d\"], patient_score[\"label\"], k=1))\n",
    "    p2d_top5.update(topk_recall(patient_score[\"p2d\"], patient_score[\"label\"], k=5))\n",
    "    p2d_top10.update(topk_recall(patient_score[\"p2d\"], patient_score[\"label\"], k=10))\n",
    "    p2d_top50.update(topk_recall(patient_score[\"p2d\"], patient_score[\"label\"], k=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2553191489361702, 0.3191489361702128)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_top10.avg, p2d_top10.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5319148936170213, 0.6382978723404256)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_top50.avg, p2d_top50.avg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symptom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
